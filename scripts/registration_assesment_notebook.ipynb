{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "registration_assesment_notebook.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e12ce2d-f5f0-4d67-9f15-f99571ed7e8b",
        "cellView": "form"
      },
      "source": [
        "#@markdown #1. Install the dependencies\n",
        "\n",
        "from tabulate import tabulate\n",
        "from astropy.visualization import simple_norm\n",
        "\n",
        "from ipywidgets import interact\n",
        "\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "import skimage.filters\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random\n",
        "import shutil \n",
        "import zipfile\n",
        "from tifffile import imread, imsave\n",
        "\n",
        "\n",
        "\n",
        "def ssim(img1, img2):\n",
        "  return structural_similarity(img1,img2,data_range=1.,full=True, gaussian_weights=True, use_sample_covariance=False, sigma=1.5)\n",
        "\n",
        "\n",
        "def normalize(x, pmin=3, pmax=99.8, axis=None, clip=False, eps=1e-20, dtype=np.float32):\n",
        "    \"\"\"This function is adapted from Martin Weigert\"\"\"\n",
        "    \"\"\"Percentile-based image normalization.\"\"\"\n",
        "\n",
        "    mi = np.percentile(x,pmin,axis=axis,keepdims=True)\n",
        "    ma = np.percentile(x,pmax,axis=axis,keepdims=True)\n",
        "    return normalize_mi_ma(x, mi, ma, clip=clip, eps=eps, dtype=dtype)\n",
        "\n",
        "\n",
        "def normalize_mi_ma(x, mi, ma, clip=False, eps=1e-20, dtype=np.float32):#dtype=np.float32\n",
        "    \"\"\"This function is adapted from Martin Weigert\"\"\"\n",
        "    if dtype is not None:\n",
        "        x   = x.astype(dtype,copy=False)\n",
        "        mi  = dtype(mi) if np.isscalar(mi) else mi.astype(dtype,copy=False)\n",
        "        ma  = dtype(ma) if np.isscalar(ma) else ma.astype(dtype,copy=False)\n",
        "        eps = dtype(eps)\n",
        "\n",
        "    try:\n",
        "        import numexpr\n",
        "        x = numexpr.evaluate(\"(x - mi) / ( ma - mi + eps )\")\n",
        "    except ImportError:\n",
        "        x =                   (x - mi) / ( ma - mi + eps )\n",
        "\n",
        "    if clip:\n",
        "        x = np.clip(x,0,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "def norm_minmse(gt, x, normalize_gt=True):\n",
        "    \"\"\"This function is adapted from Martin Weigert\"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    normalizes and affinely scales an image pair such that the MSE is minimized  \n",
        "     \n",
        "    Parameters\n",
        "    ----------\n",
        "    gt: ndarray\n",
        "        the ground truth image      \n",
        "    x: ndarray\n",
        "        the image that will be affinely scaled \n",
        "    normalize_gt: bool\n",
        "        set to True of gt image should be normalized (default)\n",
        "    Returns\n",
        "    -------\n",
        "    gt_scaled, x_scaled \n",
        "    \"\"\"\n",
        "    if normalize_gt:\n",
        "        gt = normalize(gt, 0.1, 99.9, clip=False).astype(np.float32, copy = False)\n",
        "    x = x.astype(np.float32, copy=False) - np.mean(x)    \n",
        "    gt = gt.astype(np.float32, copy=False) - np.mean(gt)    \n",
        "    scale = np.cov(x.flatten(), gt.flatten())[0, 1] / np.var(x.flatten())\n",
        "    return gt, scale * x\n",
        "\n"
      ],
      "id": "9e12ce2d-f5f0-4d67-9f15-f99571ed7e8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnrhMlxUp9dw",
        "cellView": "form"
      },
      "source": [
        "#@markdown #2. Run this cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL. \n",
        "\n",
        "#@markdown * Sign in your Google Account. \n",
        "\n",
        "#@markdown * Copy the authorization code. \n",
        "\n",
        "#@markdown * Enter the authorization code. \n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\". \n",
        "\n",
        "#mounts user's Google Drive to Google Colab.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "gnrhMlxUp9dw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKTfkXnYlDdp",
        "cellView": "form"
      },
      "source": [
        "#@markdown #3. Choose the folders that contain the data to analyse and run to load the data. One example will be displayed\n",
        "\n",
        "Source_folder = \"\" #@param{type:\"string\"}\n",
        "Result_folder = \"\" #@param{type:\"string\"}\n",
        "\n",
        "Analysis_type = \"Z-slice\" #@param [\"Max_projection\", \"Z-slice\"]\n",
        "\n",
        "Reference_Frame = \"First\" #@param [\"First\", \"Previous\"]\n",
        "\n",
        "\n",
        "#@markdown ##If not Max_projection, choose the Z plane to analyse\n",
        "Z_plane =  0#@param {type:\"number\"}\n",
        "\n",
        "# -------------------------------- Load the stack --------------------------------\n",
        "\n",
        "random_choice=random.choice(os.listdir(Source_folder))\n",
        "\n",
        "stack = imread(Source_folder+\"/\"+random_choice)\n",
        "\n",
        "print(stack.shape)\n",
        "\n",
        "if Reference_Frame == \"Previous\":           \n",
        "  print('The Previous frame will be used as a reference')\n",
        "\n",
        "if Reference_Frame == \"First\": \n",
        "  print('The First frame will be used as a reference')\n",
        "\n",
        "\n",
        "# perform the max projection\n",
        "\n",
        "if Analysis_type == \"Max_projection\":\n",
        "  #make max projection\n",
        "  maxproj = np.max(stack[:,:,:,:],axis = 1)\n",
        "  print('---------------------------')\n",
        "  print('max projection shape', maxproj.shape)\n",
        "\n",
        "\n",
        "if Analysis_type == \"Z-slice\":\n",
        "  maxproj = stack[:,Z_plane,:,:]\n",
        "\n",
        "  print('---------------------------')\n",
        "  print('Stack shape:', maxproj.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Display one image\n",
        "\n",
        "f=plt.figure(figsize=(16,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(maxproj[0], norm=simple_norm(maxproj[0], percent = 99), interpolation='nearest')\n",
        "\n",
        "plt.axis('off')\n",
        "plt.title('First frame');\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(maxproj[1], norm=simple_norm(maxproj[1], percent = 99), interpolation='nearest')\n",
        "plt.axis('off')\n",
        "plt.title('Second frame');\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "TKTfkXnYlDdp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT94nOYA7p83",
        "cellView": "form"
      },
      "source": [
        "#@markdown #4. Process the data\n",
        "\n",
        "import csv\n",
        "from skimage.metrics import structural_similarity\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "if Analysis_type == \"Max_projection\":\n",
        "  Z_plane = \"\"\n",
        "\n",
        "\n",
        "for i in os.listdir(Source_folder):\n",
        "  if not os.path.isdir(os.path.join(Source_folder,i)):\n",
        "    print('Running QC on: '+i)\n",
        "    stack = imread(Source_folder+\"/\"+i)\n",
        "\n",
        "    if Analysis_type == \"Max_projection\":\n",
        "  \n",
        "      maxproj = np.max(stack[:,:,:,:],axis = 1)\n",
        "\n",
        "    if Analysis_type == \"Z-slice\":\n",
        "      maxproj = stack[:,Z_plane,:,:]\n",
        "\n",
        "# Open and create the csv file that will contain all the QC metrics\n",
        "    with open(Result_folder+\"/\"+\"QC_metrics_\"+i+\"_\"+Analysis_type+str(Z_plane)+\"_\"+Reference_Frame+\".csv\", \"w\", newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "    # Write the header in the csv file\n",
        "        writer.writerow([\"image #\",\"Z plane\",\"Z plane + 1\", \"mSSIM\", \"NRMSE\", \"PSNR\", \"Pearson coefficient\"])  \n",
        "\n",
        "        # Initialize the lists\n",
        "        Z_plane_list = []\n",
        "        ssim_score_list = []\n",
        "        Pearson_correlation_coefficient_list = []\n",
        "          \n",
        "    # Let's loop through the provided dataset in the QC folders\n",
        "\n",
        "        for z in range(maxproj.shape[0]-1):\n",
        "\n",
        "          Z_plane_list.append(z)            \n",
        "      # -------------------------------- Load the data --------------------------------\n",
        "          if Reference_Frame == \"Previous\":           \n",
        "            test_GT = maxproj[z+1]                     \n",
        "            test_source = maxproj[z]\n",
        "\n",
        "          if Reference_Frame == \"First\":           \n",
        "            test_GT = maxproj[z+1]                     \n",
        "            test_source = maxproj[0]\n",
        "\n",
        "      # Normalize the images wrt each other by minimizing the MSE between GT and Source image\n",
        "          test_GT_norm,test_source_norm = norm_minmse(test_GT, test_source, normalize_gt=True)\n",
        "\n",
        "      # -------------------------------- Calculate the metric maps and save them --------------------------------\n",
        "\n",
        "      # Calculate the SSIM maps\n",
        "          index_SSIM_GTvsSource, img_SSIM_GTvsSource = ssim(test_GT_norm, test_source_norm)\n",
        "\n",
        "          ssim_score_list.append(index_SSIM_GTvsSource)\n",
        "\n",
        "      #Save ssim_maps\n",
        "\n",
        "            #img_SSIM_GTvsSource_8bit = (img_SSIM_GTvsSource* 255).astype(\"uint8\")\n",
        "            #io.imsave(QC_model_path+'/'+QC_model_name+\"/Quality Control/\"+str(checkpoints)+\"/SSIM_GTvsSource_\"+shortname_no_PNG+'.tif',img_SSIM_GTvsSource_8bit)\n",
        "      \n",
        "      # Calculate the Root Squared Error (RSE) maps\n",
        "          img_RSE_GTvsSource = np.sqrt(np.square(test_GT_norm - test_source_norm))\n",
        "\n",
        "      # Save SE maps\n",
        "            #img_RSE_GTvsSource_8bit = (img_RSE_GTvsSource* 255).astype(\"uint8\")\n",
        "            #io.imsave(QC_model_path+'/'+QC_model_name+\"/Quality Control/\"+str(checkpoints)+\"/RSE_GTvsSource_\"+shortname_no_PNG+'.tif',img_RSE_GTvsSource_8bit)\n",
        "\n",
        "\n",
        "      # -------------------------------- Calculate the RSE metrics and save them --------------------------------\n",
        "\n",
        "      # Normalised Root Mean Squared Error (here it's valid to take the mean of the image)\n",
        "          NRMSE_GTvsSource = np.sqrt(np.mean(img_RSE_GTvsSource))\n",
        "        \n",
        "      # We can also measure the peak signal to noise ratio between the images\n",
        "          PSNR_GTvsSource = psnr(test_GT_norm,test_source_norm,data_range=1.0)\n",
        "\n",
        "\n",
        "          cm1 = np.corrcoef(test_GT_norm.flat, test_source_norm.flat) #outputs a flat number\n",
        "          r1 = cm1[0, 1]\n",
        "          Pearson_correlation_coefficient_list.append(r1)\n",
        "\n",
        "          writer.writerow([i,str(z),str(z+1),str(index_SSIM_GTvsSource),str(NRMSE_GTvsSource),str(PSNR_GTvsSource),str(r1)])\n",
        "\n",
        "# All data is now processed saved\n",
        "\n",
        "\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "\n",
        "print('--------------------------------------------------------------')\n",
        "@interact\n",
        "def show_QC_results(file = os.listdir(Result_folder)):\n",
        "  df = pd.read_csv (Result_folder+\"/\"+file)\n",
        "  df.set_index(\"image #\", inplace=True)\n",
        "  print(tabulate(df, headers='keys', tablefmt='psql'))\n",
        "\n",
        "  Z_plane_list = df['Z plane + 1'].values.tolist()\n",
        "  ssim_score_list = df['mSSIM'].values.tolist()\n",
        "  Pearson_correlation_coefficient_list = df['Pearson coefficient'].values.tolist()\n",
        "\n",
        "# -------------------------------- Display --------------------------------\n",
        "\n",
        "  plt.figure(figsize=(20,5))\n",
        "  plt.plot(Z_plane_list, ssim_score_list, label=\"SSIM\")\n",
        "  plt.title('Z plane vs. SSIM')\n",
        "  plt.ylabel('SSIM')\n",
        "  plt.xlabel('Z plane')\n",
        "  plt.legend()\n",
        "#plt.savefig(full_QC_model_path+'/Quality Control/SSIMvsCheckpoint_data.png',bbox_inches='tight',pad_inches=0)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(20,5))\n",
        "  plt.plot(Z_plane_list, Pearson_correlation_coefficient_list, label=\"Pearson coefficient\")\n",
        "  plt.title('Z plane vs. Pearson coefficient')\n",
        "  plt.ylabel('Pearson coefficient')\n",
        "  plt.xlabel('Z plane')\n",
        "  plt.legend()\n",
        "#plt.savefig(full_QC_model_path+'/Quality Control/lpipsvsCheckpoint_data.png',bbox_inches='tight',pad_inches=0)\n",
        "  plt.show()\n"
      ],
      "id": "dT94nOYA7p83",
      "execution_count": null,
      "outputs": []
    }
  ]
}